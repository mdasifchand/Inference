{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO download the model\n",
    "#TODO run object classification with softmax\n",
    "#TODO make comments more readable later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "assert(torch.cuda.is_available() == True) # this is important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get that progress bar in the jupyter notebook (with VScode and docker)\n",
    "from ipywidgets import IntProgress \n",
    "#conda install -c anaconda ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/light/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06404308c4964573a3ee57f09aa55ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "img = Image.open(\"U.jpeg\")\n",
    "transform = transforms.Compose([ transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(),\n",
    "    transforms.Normalize( (0.485, 0.456, 0.406), (0.229,0.224,0.225))]) # ETL\n",
    "\n",
    "img = transform(img)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_batch = torch.unsqueeze(img,0) # adds that extra dimension in the beginnning\n",
    "img_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1792e-01, -1.0081e+00, -2.3459e+00, -2.6079e+00, -2.4024e+00,\n",
       "         -7.7881e-01, -2.8961e+00, -1.7883e+00,  8.8050e-01, -9.9223e-01,\n",
       "          8.7115e-02, -1.1778e+00,  8.7190e-01, -2.0387e+00, -5.7940e-01,\n",
       "          3.2136e-01,  6.2941e-01,  1.5505e+00, -8.3795e-01, -2.8367e+00,\n",
       "         -4.0389e-02,  1.0677e+00, -1.2064e+00, -1.0482e+00, -1.9410e+00,\n",
       "         -1.7625e+00, -1.0869e+00, -1.4838e+00, -2.3074e+00, -2.5188e+00,\n",
       "         -3.2299e-01, -2.9863e+00, -9.7032e-01, -3.8036e+00, -1.6058e+00,\n",
       "          1.4168e-01,  4.0268e-01, -5.1626e-01,  1.7253e+00,  1.0670e+00,\n",
       "          8.5885e-01,  1.7392e+00,  9.8292e-01,  1.0110e+00,  8.1320e-01,\n",
       "         -1.6250e+00,  9.5528e-01,  5.7576e-01, -1.5660e-01, -3.1129e+00,\n",
       "         -2.3350e+00,  3.2468e-01, -6.4832e-01, -1.6676e+00, -9.0784e-02,\n",
       "         -1.1626e+00, -2.2677e+00, -2.4179e+00,  3.0206e-01,  1.6698e+00,\n",
       "          2.5563e-01, -8.0776e-01,  1.0236e+00,  4.0955e-01,  3.8901e-01,\n",
       "         -2.2554e+00,  1.1203e+00,  8.3437e-02,  1.6658e-01, -3.2559e+00,\n",
       "         -3.5655e+00, -3.0676e+00, -1.5270e+00, -1.6442e+00, -1.3222e+00,\n",
       "         -3.4371e+00, -1.3041e+00, -1.5048e+00, -2.4736e-01, -8.6316e-01,\n",
       "         -1.4396e+00, -3.1421e+00,  3.0970e+00,  1.0084e+00, -5.6230e-01,\n",
       "         -1.8103e+00,  3.1458e+00, -1.8790e+00,  9.8069e-01, -2.5899e+00,\n",
       "         -9.1173e-01,  1.2445e+00,  1.5079e+00, -2.5722e+00,  2.9401e-01,\n",
       "         -9.9502e-01, -3.2155e-01, -5.3981e-01, -7.2557e-01,  4.6748e-01,\n",
       "         -4.9079e+00, -1.4700e+00, -8.5726e-01,  5.6857e-01,  6.0547e-01,\n",
       "         -1.1042e+00,  2.8120e-01, -4.6087e+00, -1.8000e+00, -6.6103e-01,\n",
       "         -3.4290e+00, -1.6466e+00, -1.4018e+00,  5.7960e-01,  1.5314e+00,\n",
       "         -2.6554e+00, -2.9254e+00,  3.9186e-01, -1.5097e-01, -3.1996e+00,\n",
       "         -2.6810e+00, -2.5884e+00, -8.4541e-01, -2.4981e+00, -6.6508e-01,\n",
       "         -1.7079e+00, -1.3216e+00, -3.1468e+00, -2.9154e+00, -3.1642e+00,\n",
       "         -5.5336e-01, -3.0315e-01, -8.9275e-01,  4.0184e+00, -4.5069e-01,\n",
       "         -1.3144e+00,  5.1210e-02, -2.9153e+00,  1.2380e+00, -2.9654e+00,\n",
       "         -2.3508e+00, -9.0061e-01, -3.4047e+00, -4.3834e+00, -3.3821e+00,\n",
       "         -1.5747e+00, -3.1981e+00, -1.5189e+00, -8.1891e-01, -2.1979e+00,\n",
       "          1.4687e+00,  2.5627e+00,  1.3891e+00, -1.4486e+00,  1.5056e+00,\n",
       "          9.5104e-01, -9.6248e-01, -4.5571e-01, -4.5430e-01,  1.5109e-01,\n",
       "         -7.5110e-01, -6.4052e-02, -1.7271e-01,  2.9492e-01, -1.5458e+00,\n",
       "         -2.8269e+00, -2.5779e+00, -2.0224e+00,  1.3204e+00, -2.1591e+00,\n",
       "         -3.0616e+00, -8.6922e-01, -7.6819e-01,  1.6171e+00, -8.8553e-01,\n",
       "         -1.0758e+00, -5.1979e-01, -3.7810e+00, -5.4218e-02, -1.7298e+00,\n",
       "         -7.9077e-01, -2.3749e+00,  6.5895e-01, -2.7588e+00, -1.7687e+00,\n",
       "          7.4515e-01,  2.4929e+00, -1.7143e-01, -1.2242e+00, -1.1669e-01,\n",
       "         -2.2752e+00, -2.4446e+00,  8.6924e-02,  9.9043e-01,  9.9764e-02,\n",
       "          1.1377e-01, -1.7730e+00, -2.0722e+00, -2.1669e+00, -5.4723e-01,\n",
       "          6.0634e-01, -2.2485e+00, -5.5774e-01, -1.0974e+00,  1.1552e+00,\n",
       "         -1.2014e+00, -1.1721e+00,  2.3451e+00,  8.7584e-01,  5.4990e-01,\n",
       "         -1.5797e+00,  2.5433e+00, -1.9451e+00, -8.2597e-01, -1.5326e+00,\n",
       "          3.2052e-01,  1.0279e-01, -1.7812e+00, -9.6093e-02,  1.8074e-01,\n",
       "          1.0587e+00, -2.1531e+00, -1.8543e+00,  5.9721e-01, -2.9831e-01,\n",
       "          2.0152e+00, -7.9026e-01,  2.3187e+00, -1.7544e+00, -2.3040e+00,\n",
       "         -6.9974e-01,  7.5908e-01,  7.3055e-02, -1.5892e+00, -1.2362e+00,\n",
       "          1.0201e+00, -9.3506e-01, -1.4202e+00,  7.9487e-02,  1.0689e-01,\n",
       "          4.5628e-01, -3.8582e-01, -1.2852e+00, -1.0431e-01, -8.0391e-01,\n",
       "          1.0232e+00, -7.9813e-01, -4.8039e-02,  9.5345e-01, -2.4654e-02,\n",
       "          1.2281e+00, -1.0106e+00, -7.5562e-01,  1.1668e+00, -4.1342e-01,\n",
       "          1.2124e+00, -3.8999e-01, -1.7965e+00, -1.6574e+00,  2.7732e+00,\n",
       "          8.1972e-01, -1.0749e+00,  1.2851e+00,  4.4446e+00,  3.9049e+00,\n",
       "         -1.1359e+00, -2.6702e+00, -3.6385e+00, -7.3476e-01, -1.7500e+00,\n",
       "         -1.8314e+00,  1.5769e+00,  4.3784e-01,  3.0637e+00,  3.6928e+00,\n",
       "         -1.3127e+00, -3.4566e-01,  5.6383e+00,  5.9222e+00,  1.6937e+00,\n",
       "          3.3719e+00,  1.0210e+01,  1.0399e+01,  6.1719e+00,  5.0366e+00,\n",
       "          9.6448e+00,  5.8125e+00,  1.0082e+01,  2.3143e+00,  1.4680e+00,\n",
       "          3.3290e+00,  3.0705e+00,  7.1090e+00,  1.8568e+00, -1.0532e+00,\n",
       "         -7.6613e-01, -1.8718e+00, -1.9154e+00,  3.1247e+00,  1.7687e+00,\n",
       "         -1.9397e+00, -3.3378e+00, -2.8007e+00, -3.8630e+00, -4.0197e+00,\n",
       "         -2.5633e+00,  2.6549e-01, -4.4418e+00, -3.3313e+00, -2.0613e+00,\n",
       "         -1.8099e+00, -1.2602e+00, -1.8113e+00,  2.9851e-02, -2.5766e+00,\n",
       "         -1.2832e+00, -3.3775e+00, -2.3852e+00, -1.8485e+00,  1.3146e+00,\n",
       "          6.6898e-01, -3.5932e+00,  1.4054e+00, -1.5033e+00, -5.0284e-01,\n",
       "         -1.3875e-01,  2.7752e+00, -2.8651e+00, -2.0992e+00, -2.6976e+00,\n",
       "          2.6549e+00,  2.3919e+00,  2.6796e+00,  1.1168e+00, -1.3633e+00,\n",
       "          1.2051e+00,  7.7529e-02,  3.7811e-01, -1.2971e+00, -3.4990e-03,\n",
       "          3.6979e-01,  8.6336e-03, -1.2885e+00, -2.2085e+00, -2.2896e+00,\n",
       "         -2.3267e+00, -1.7615e+00, -3.5396e+00, -3.3218e+00, -3.8305e+00,\n",
       "         -1.0307e+00, -1.4397e+00,  8.5800e-01,  2.0282e+00, -2.9013e+00,\n",
       "         -6.1793e-01,  5.9782e+00,  4.2137e+00,  4.8626e+00,  2.9860e+00,\n",
       "          2.9939e+00,  8.7737e-01,  7.9656e-01, -2.3910e-01, -1.6768e+00,\n",
       "          1.0137e+00, -2.4111e+00, -2.5263e+00, -3.2636e-01, -6.8246e-01,\n",
       "          4.7686e-01,  2.7434e+00, -3.4174e+00,  2.0802e+00, -1.0703e-01,\n",
       "         -3.1314e+00,  8.6646e-01,  2.7348e-01,  1.5885e+00, -3.1720e-01,\n",
       "          6.3001e-01,  5.3436e-02,  6.6541e-01,  1.4842e+00,  1.7987e+00,\n",
       "         -1.3451e+00, -1.0231e+00,  3.7204e+00, -7.0703e-01,  1.0926e+00,\n",
       "         -1.9654e+00,  7.1578e-01, -8.2546e-01, -4.0527e+00, -1.9578e+00,\n",
       "          1.0759e+00, -3.8881e+00, -4.2526e+00, -6.5384e-01, -5.3380e-01,\n",
       "         -9.3774e-01, -2.4836e+00, -1.1425e-01, -2.2414e+00, -1.0871e+00,\n",
       "         -3.9192e-01,  6.2667e-01, -2.2881e+00, -7.2729e-02,  1.1667e+00,\n",
       "         -1.6914e-01,  1.5491e+00,  4.9132e+00, -4.0392e-01,  3.1433e+00,\n",
       "         -6.8152e-01,  5.5982e-01,  1.3456e+00, -4.1882e-01,  4.6800e+00,\n",
       "          3.5342e-02, -2.7124e-01,  1.4077e+00,  6.6531e-01, -5.6396e-01,\n",
       "         -1.1425e+00, -2.1670e-01,  4.5539e+00,  5.4699e+00,  8.0475e-01,\n",
       "          2.4508e-02,  1.7245e+00, -1.9105e+00,  1.1113e+00,  3.7546e+00,\n",
       "          4.8982e+00, -2.8916e-01, -1.6076e+00,  2.1183e+00, -1.3436e+00,\n",
       "          1.5718e-01, -1.7472e-01,  1.4324e+00,  2.5474e+00,  5.6665e-01,\n",
       "          7.1349e-01,  2.0901e-01, -2.0403e+00, -6.5698e-01,  4.2982e-01,\n",
       "         -1.0808e+00, -2.2764e+00,  3.0276e+00,  2.6210e+00,  4.9618e-01,\n",
       "         -8.2624e-01,  1.6332e+00,  2.2004e+00, -2.4739e+00,  8.6531e-01,\n",
       "         -7.2148e-01, -1.7763e+00,  5.1186e+00,  6.5108e+00, -1.0646e+00,\n",
       "          5.2315e-01, -2.6188e+00, -1.3733e+00, -1.3697e+00,  2.3265e+00,\n",
       "         -9.1664e-02, -1.4705e+00,  2.3969e+00,  9.7029e-01, -1.0225e+00,\n",
       "          1.1832e-01, -1.4313e+00, -1.3917e-03,  5.4202e+00,  7.5702e-01,\n",
       "         -5.6350e-01, -1.9201e+00, -2.5631e+00, -2.6059e+00,  2.3606e+00,\n",
       "         -2.4998e+00, -1.2202e+00,  6.9377e-01, -8.1198e-01, -1.8435e+00,\n",
       "         -1.6109e+00,  5.8312e-01, -7.4643e-02, -1.3562e-01, -3.7821e-01,\n",
       "         -1.6200e+00,  2.4392e-01, -1.0410e+00, -2.4511e+00, -1.8395e-01,\n",
       "         -1.1576e+00,  6.3324e-01,  2.1642e+00,  9.3859e-01,  1.1555e+00,\n",
       "         -3.6362e-02, -8.6144e-01, -9.2843e-01,  2.0670e+00, -1.9695e+00,\n",
       "         -7.4915e-01, -2.0741e+00, -1.4361e-01, -2.6824e+00,  2.6631e+00,\n",
       "          5.6569e-01,  2.7774e+00,  5.7950e-02,  2.1879e+00,  4.5702e+00,\n",
       "          2.7978e-01, -7.9898e-01,  2.9250e+00,  5.4058e-01, -1.0111e+00,\n",
       "         -8.6658e-01,  2.1836e+00,  1.1083e+00, -1.8253e+00,  1.7152e+00,\n",
       "          2.0003e-01, -6.7405e-01,  9.2647e-01, -4.5728e-03,  3.3076e+00,\n",
       "         -1.0285e+00,  1.1480e+00, -3.4114e+00, -1.0106e+00,  5.3254e+00,\n",
       "         -1.9121e+00,  2.4956e-01, -7.3362e-01,  3.8657e+00,  1.7766e+00,\n",
       "          1.1278e+00, -1.4713e+00, -3.0963e+00, -7.8234e-01,  1.4047e-01,\n",
       "          8.2923e-01,  9.0604e-01,  1.4861e+00,  3.0608e+00, -3.5733e+00,\n",
       "         -2.0242e+00,  1.8529e+00, -2.3183e-01, -1.7694e+00,  2.8828e+00,\n",
       "         -6.9530e-01,  2.1898e-01, -1.0904e+00, -1.6110e+00, -3.0484e+00,\n",
       "          1.0467e+00, -1.8663e+00,  1.7733e+00, -1.8920e+00, -8.1457e-01,\n",
       "          5.5255e-01, -1.0759e+00,  5.4764e-01, -2.6463e+00,  2.2913e+00,\n",
       "         -2.1829e+00, -2.1617e+00, -4.6443e-01, -1.6455e+00, -2.5336e+00,\n",
       "          1.7287e+00, -1.1618e+00,  2.7292e+00,  5.7526e-01, -2.3223e-01,\n",
       "         -4.9016e-01, -1.0098e-01,  1.3925e+00,  6.8156e+00, -6.1018e-01,\n",
       "         -2.0168e-01,  1.8378e+00, -8.1313e-01, -1.1623e-02, -2.2011e+00,\n",
       "         -9.7974e-02,  2.2234e+00, -1.8566e+00, -2.4929e+00,  2.4341e-01,\n",
       "          1.3411e+00,  8.5204e-01,  2.8527e+00, -1.8025e-01, -6.4681e-01,\n",
       "         -2.4570e+00,  1.4138e+00,  1.3790e+00,  1.7964e+00, -4.3496e+00,\n",
       "          4.0885e-01,  1.3013e+00, -6.9128e-01, -2.0562e+00, -2.5610e+00,\n",
       "          1.4358e+00, -2.0893e+00, -2.6173e-01,  2.5136e+00,  4.5153e-01,\n",
       "          3.9718e+00,  1.6859e+00,  1.4537e+00, -1.6485e+00,  8.1322e-01,\n",
       "          9.3045e-01, -1.4656e+00, -3.5033e+00, -1.9936e+00, -2.3720e+00,\n",
       "          7.7921e-01,  2.3433e+00, -5.9727e-01,  2.7467e-01,  2.3561e+00,\n",
       "          1.9863e+00,  1.8057e+00, -1.0865e-01,  1.2042e+00,  3.5782e-01,\n",
       "         -9.5523e-01,  4.0353e-01, -1.7180e+00, -1.4531e+00, -2.2039e+00,\n",
       "         -1.8087e+00,  1.1885e+00,  2.1621e+00,  8.7646e-02, -1.6430e+00,\n",
       "         -2.3001e+00,  1.4725e+00, -1.2280e+00,  2.2785e+00, -1.7122e+00,\n",
       "          8.8065e-01,  4.9860e-01, -6.7987e-01, -3.3325e-01,  4.2143e+00,\n",
       "          8.9095e-01, -1.2293e+00,  1.5514e+00, -1.9703e+00,  2.0331e+00,\n",
       "          3.0319e+00,  7.1125e-01, -6.5678e-01, -2.0667e+00,  7.9915e-01,\n",
       "          2.4437e+00,  1.2893e+00,  3.7358e-01,  2.0226e+00,  9.9996e-01,\n",
       "          6.5726e-01,  1.0188e+00,  5.0941e-01,  6.8329e-01, -1.6792e+00,\n",
       "          1.9457e+00,  1.5947e+00, -1.0837e-01, -1.5777e+00,  2.9297e-04,\n",
       "         -3.3227e+00,  8.6694e-01, -2.4972e+00, -1.9708e+00, -1.7405e-01,\n",
       "         -1.3109e+00,  4.9863e-01,  1.1589e+00,  2.4956e+00, -2.2851e+00,\n",
       "         -2.2125e+00,  1.2094e+00, -3.4831e-01, -2.6826e+00,  6.7443e-02,\n",
       "          3.5989e+00, -4.6067e-01,  3.0466e-01,  4.5923e-01, -1.5009e+00,\n",
       "         -2.0889e+00,  8.5094e-01,  7.4147e-01,  5.6572e-01,  9.0286e-01,\n",
       "          1.1834e+00,  3.1202e-01,  3.0621e-01,  2.6991e+00,  4.7697e-01,\n",
       "         -1.0662e+00, -3.6774e-01,  3.3651e-01, -8.3146e-01,  1.9832e-01,\n",
       "         -4.0347e-01,  2.4385e-01,  3.2242e+00,  1.6969e+00,  4.7783e-01,\n",
       "          2.1849e+00, -1.0272e+00, -6.2298e-02,  5.8203e+00,  1.3240e+00,\n",
       "         -8.8852e-01,  2.2073e+00, -2.4450e+00,  1.6851e+00, -2.6309e+00,\n",
       "          1.1111e+00, -1.9121e-01,  1.2587e+00,  4.9314e+00,  2.3070e-01,\n",
       "         -3.3178e-01,  8.2094e-01,  4.7949e+00, -2.1158e+00, -9.8575e-02,\n",
       "         -2.9062e+00, -1.2863e+00,  1.7730e+00,  1.3328e+00, -4.1185e-01,\n",
       "          2.6204e+00, -1.9450e+00,  1.0367e+00,  1.4925e+00, -8.5788e-01,\n",
       "         -9.5286e-01,  4.4964e+00, -9.0235e-01,  1.8301e+00, -2.2988e+00,\n",
       "          2.2454e+00,  2.1258e+00,  2.2606e-01, -1.2076e+00, -1.5111e-01,\n",
       "          2.9564e+00,  1.0937e+00, -5.9334e-01,  1.8500e+00,  3.0426e+00,\n",
       "          1.6981e+00, -1.1828e+00,  5.7902e-01, -3.5253e-01, -3.0678e-01,\n",
       "          1.3157e+00, -1.7633e+00, -1.6488e+00,  4.8509e+00, -2.9764e+00,\n",
       "          2.2102e+00, -2.1643e+00,  3.9932e+00, -4.1766e-02,  5.1306e-01,\n",
       "         -1.4836e+00,  1.5101e+00, -9.0784e-01, -1.8982e+00,  5.4987e-01,\n",
       "          5.1024e+00,  8.8140e-01,  3.9924e+00,  2.2469e+00,  2.0630e+00,\n",
       "          2.3866e-01,  7.4262e-01,  3.7218e+00, -1.9359e+00,  1.5747e+00,\n",
       "         -2.2175e+00,  1.9947e+00, -1.7099e+00, -1.5275e+00,  2.4882e+00,\n",
       "          2.8821e+00,  2.8164e+00,  7.3253e-01,  1.2246e+00,  1.9386e+00,\n",
       "          9.0049e-01,  1.6785e+00, -2.6775e+00,  2.0919e+00,  4.4449e-01,\n",
       "         -5.0730e-01, -1.3013e+00, -1.4429e+00,  8.8252e-01, -2.4124e+00,\n",
       "         -3.6418e+00, -9.9372e-01, -7.8564e-01,  1.5513e-01, -2.4528e-01,\n",
       "         -1.0333e-01, -1.8078e+00,  6.8145e-01,  1.4647e+00, -1.6168e+00,\n",
       "          7.0806e-01,  1.4312e+00, -9.6157e-01, -1.1928e-01, -1.0786e+00,\n",
       "          8.1657e-01, -9.4912e-02,  2.6224e-01,  3.1078e+00, -1.9644e+00,\n",
       "          4.0633e+00,  3.4800e+00,  2.6217e+00,  2.8733e+00, -1.9182e+00,\n",
       "          6.6881e-01,  8.8236e-01, -1.2208e+00, -1.2434e+00,  1.5333e-01,\n",
       "         -4.5995e-01,  1.9705e+00,  3.7825e+00, -1.4214e-01, -1.9599e+00,\n",
       "          9.6697e-01,  2.4499e-01, -2.7796e+00,  2.4028e+00,  2.5969e+00,\n",
       "          1.2808e+00,  5.6469e+00, -1.0852e+00, -6.4679e-01, -1.6099e+00,\n",
       "          8.5629e-01,  4.3682e-01, -2.2414e-01,  1.5981e+00, -3.0614e+00,\n",
       "          2.9535e+00,  4.6569e+00,  1.7567e-01, -2.4138e+00, -2.3386e+00,\n",
       "         -9.4757e-01,  5.5840e+00, -1.9141e+00, -1.4091e-01,  7.1013e-01,\n",
       "          2.5568e+00,  6.5720e-01,  1.0672e+00,  2.5697e+00, -1.6543e+00,\n",
       "          2.0658e+00, -7.9790e-01, -1.1199e+00, -8.3946e-01, -9.6175e-01,\n",
       "          4.7186e-01, -7.8858e-02, -1.9112e-01,  9.8229e-01,  6.8560e-01,\n",
       "         -1.0468e+00,  2.9209e+00,  3.8776e+00,  1.3630e+00,  3.6803e+00,\n",
       "         -2.6445e-01,  3.3403e-01,  9.7770e-02, -2.0531e-01,  3.6326e+00,\n",
       "          1.2072e+00, -1.6114e-01,  1.8514e+00, -1.9088e+00,  1.9236e+00,\n",
       "          9.1117e-01,  9.9083e-01,  1.2610e+00, -3.9447e-01,  1.8150e+00,\n",
       "         -2.1779e+00,  1.1051e+00,  3.0030e-01,  2.6922e+00,  3.4758e-01,\n",
       "         -1.3269e+00, -5.4762e-01, -2.2349e+00,  1.7954e-01, -1.2112e-01,\n",
       "          1.3552e-01,  1.0908e+00, -1.0888e+00, -2.3134e+00,  1.4854e+00,\n",
       "          5.3798e-01, -6.3400e-01, -2.2136e+00, -2.5418e+00, -9.2642e-01,\n",
       "         -3.8098e-01, -3.2507e-01,  2.0620e+00, -2.9096e-01,  3.3246e+00,\n",
       "          8.1112e-01, -2.8695e-01,  1.4941e+00,  1.5206e+00, -1.2250e+00,\n",
       "          1.4372e+00, -1.0388e+00,  6.8543e-01,  1.6553e+00,  1.2702e+00,\n",
       "          1.6485e+00,  9.6530e-02,  3.7080e-01,  7.1043e-01,  1.1426e+00,\n",
       "          7.2658e-01, -8.9715e-01, -5.5790e-01,  9.9799e-01, -2.3212e+00,\n",
       "         -1.0727e+00, -2.0175e+00, -2.8408e-01, -1.8942e+00,  2.8029e+00,\n",
       "         -1.5323e+00,  9.1308e-01,  1.4423e-01,  2.6789e+00,  2.0669e+00,\n",
       "         -6.4078e-01,  2.7863e-01,  3.4155e-01, -1.5958e+00, -2.8987e+00,\n",
       "          1.2496e+00, -2.3170e+00,  4.9637e-01,  2.2068e+00, -1.5066e+00,\n",
       "         -3.1028e+00, -1.6645e+00, -3.0771e+00, -1.7069e+00, -3.1960e-01,\n",
       "         -1.3430e+00, -1.2502e+00,  2.4665e+00, -5.3306e-01, -2.4280e+00,\n",
       "         -1.0968e+00, -8.9317e-01, -1.3329e+00, -6.2329e-01, -5.6945e-01,\n",
       "         -4.1432e-01,  8.2184e-01, -2.2257e-01,  2.8284e+00,  2.0392e+00]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's do the final part\n",
    "# at inference time we don't need gradients associated with the tensor\n",
    "# so we can deactivate it for now\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(img_batch)\n",
    "probs = torch.nn.functional.softmax(outputs[0],0) # this results in a big vector with about 1000 classes\n",
    "# ideally one of these classes is the right prediction\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's associate index with actual name of class from dictionary\n",
    "import pandas as pd\n",
    "categories = pd.read_csv(\"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\", header=None)\n",
    "# categories has dictionary attributes like : { '0': 'fish} for example\n",
    "categories.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tench\n"
     ]
    }
   ],
   "source": [
    "categories[0] # has all the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3 = 3 # top k predictions\n",
    "prob, class_number = torch.topk(probs, top3) # extract top 3 highest probablities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%43 probability for class  Persian cat\n",
      "%25 probability for class  Egyptian cat\n",
      "%4 probability for class  tiger cat\n"
     ]
    }
   ],
   "source": [
    "for i in range(top3):\n",
    "    probability = prob[i].item()\n",
    "    class_name = categories[0][int(class_number[i])]\n",
    "    print( \"%{} probability for class  {}\".format (int(probability*100), class_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
